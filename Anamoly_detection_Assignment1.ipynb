{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "299ce35e-9507-452b-8dd2-7514bc1f2d51",
   "metadata": {},
   "source": [
    "# Anamoly detection in Unsupervised learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b807ec7c-d7f8-4b5d-afd0-705a1f609fc1",
   "metadata": {},
   "source": [
    "# Q1. What is anomaly detection and what is its purpose?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8edf93e-d3c1-49cb-936d-d4f3096e1711",
   "metadata": {},
   "source": [
    "Anomaly detection is examining specific data points and detecting rare occurrences that seem suspicious because they’re different from the established pattern of behaviors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f1c9651-e581-432b-8d57-bfb634dac2c0",
   "metadata": {},
   "source": [
    "The main Purpose we use anomaly detection is to find things that are unusual or unexpected in our data (to find outliers )."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c376e93-220d-49c5-aa80-76213a2ae40b",
   "metadata": {},
   "source": [
    "# Q2. What are the key challenges in anomaly detection?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6afe217-f9c7-4fb9-8616-0fa76508b133",
   "metadata": {},
   "source": [
    "These are some the key challenges in anomaly detection that are :-\n",
    "1. Data quality :- Data quality problems can include Null data or incomplete datasets, Inconsistent data formats, Duplicate data, Different scales of measurement, Human error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7bd495e-462d-4dc0-9e6b-a2acdc44c9f2",
   "metadata": {},
   "source": [
    " solve data quality issues :-\n",
    "    Discard or fill null values,\n",
    "    Standardize all data formats,\n",
    "    Remove duplicate data,\n",
    "    Pre-process your input features,\n",
    "    Reduce dependency on data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b78bbbb8-ba66-4c78-8b12-3db590a42e7c",
   "metadata": {},
   "source": [
    "2. Noise and Uncertainty:- Real-world data often contain noise and uncertainties, which can make it challenging to distinguish genuine anomalies from random fluctuations or measurement errors. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aebd58fa-1d6f-40c4-8fb7-78283b04e74e",
   "metadata": {},
   "source": [
    "3. Labeling Anomalies:\n",
    "Problem: It's like trying to find something strange in a picture without knowing what strange things look like.\n",
    "Example: Imagine looking for unusual clouds in the sky but not knowing which clouds are considered strange."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d908f3-ec34-43c5-9240-542577a50f6c",
   "metadata": {},
   "source": [
    "4.Scalability and Efficiency:\n",
    "Problem: It's like trying to count all the grains of sand on a beach by hand – it takes too much time and effort.<br>\n",
    "Example: As data gets bigger and more complex, it becomes harder for anomaly detection algorithms to keep up and work quickly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475c6f9a-46af-4a33-a550-72bce754f7ad",
   "metadata": {},
   "source": [
    "# Q3. How does unsupervised anomaly detection differ from supervised anomaly detection?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e30b4f-79ba-4f4d-b322-f33200cde2d2",
   "metadata": {},
   "source": [
    "1.Data Requirement:\n",
    "Unsupervised: You don't need labeled examples because the algorithm figures out anomalies based on differences from the majority of the data.\n",
    "<br>Supervised: You need labeled examples to train the model to recognize anomalies based on predefined patterns.\n",
    "\n",
    "<br>2. Detection Approach:\n",
    "Unsupervised: You're looking for things that stand out as different from the rest of the data without knowing what specifically to look for.\n",
    "<br>Supervised: You're looking for specific patterns or characteristics that indicate an anomaly based on examples you've seen before."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5046a6-dca8-49b8-9e8c-5f0792878b9d",
   "metadata": {},
   "source": [
    "# Q4. What are the main categories of anomaly detection algorithms?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1501b5b7-15dc-491f-bf2d-e311ff658341",
   "metadata": {},
   "source": [
    "the main categories of anomaly detection algorithms are :-\n",
    "1. Unsupervised Anomaly Detection:\n",
    "What it does: It finds weird things in data without being told what weird things to look for.\n",
    "How it works: It looks for data points that are very different from the rest, like spotting a purple cow in a field of white cows.\n",
    "Example: If most people buy 1-2 items at a store, but someone suddenly buys 100 items, that would be flagged as unusual.\n",
    "<br>\n",
    "2. Supervised Anomaly Detection:\n",
    "What it does: It learns from examples of normal and weird things to find more weird things.\n",
    "How it works: It's like teaching a dog to bark when it sees a squirrel – you show it pictures of squirrels and non-squirrels until it learns the difference.\n",
    "Example: If you have a list of known fraudulent transactions, the model learns to recognize similar patterns in new transactions.\n",
    "<br>\n",
    "3. Semi-supervised Anomaly Detection:\n",
    "\n",
    "What it does: It uses a mix of labeled and unlabeled data to find anomalies.\n",
    "How it works: It's like having some clues about where to find hidden treasures, but not knowing exactly where they are.\n",
    "Example: You have a few examples of fraudulent transactions, but most transactions are normal. The model learns from both to detect anomalies better."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa746ef-6f11-48c9-9036-caef9c4525ae",
   "metadata": {},
   "source": [
    "# Q5. What are the main assumptions made by distance-based anomaly detection methods?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48bb2cfa-fbdc-44ab-8310-62a61a0ae55a",
   "metadata": {},
   "source": [
    " the main assumptions made by distance-based anomaly detection methods:\n",
    "\n",
    "Assumption of Normality:\n",
    "\n",
    "Distance-based methods often assume that normal data points are clustered together tightly, forming dense regions in the data space. Anomalies, on the other hand, are assumed to be isolated or distant from the majority of normal data points.\n",
    "Example: In a two-dimensional scatter plot, normal data points are expected to form clusters, while anomalies may appear as outliers far away from these clusters.\n",
    "<br>\n",
    "\n",
    "Euclidean Distance Metric:\n",
    "\n",
    "Many distance-based anomaly detection methods rely on the Euclidean distance metric to measure the distance between data points in continuous feature spaces.\n",
    "Example: The Euclidean distance between two points (x1, y1) and (x2, y2) in a two-dimensional space is calculated as the square root of the sum of the squared differences in each dimension: sqrt((x2 - x1)^2 + (y2 - y1)^2).\n",
    "\n",
    "<br>Uniform Data Distribution:\n",
    "\n",
    "Distance-based methods often assume a uniform distribution of normal data points in the feature space, where anomalies are relatively rare and distinct from the majority of normal instances.\n",
    "Example: In a dataset representing customer transaction amounts, normal transactions are expected to be distributed evenly across different value ranges, while anomalies may occur infrequently and at extreme values.\n",
    "\n",
    "<br> Threshold-based Detection:\n",
    "\n",
    "Distance-based anomaly detection methods typically involve setting a threshold distance beyond which data points are considered anomalies. Instances that exceed this threshold are flagged as anomalies.\n",
    "Example: If the average distance between data points is calculated, anomalies may be identified as those instances with distances above a certain multiple of the average distance.\n",
    "\n",
    "<br>Assumption of Anomaly Separability:\n",
    "\n",
    "These methods assume that anomalies are sufficiently separated from normal instances in the feature space, allowing them to be distinguished based on distance.\n",
    "Example: Anomalies are expected to have substantially higher distances from the centroid or cluster center of normal instances, making them stand out as outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641df13e-1f6d-4242-b6db-78a68712483e",
   "metadata": {},
   "source": [
    "# Q6. How does the LOF algorithm compute anomaly scores ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c5671a0-16a6-46f0-b53a-ed9088290568",
   "metadata": {},
   "source": [
    "The LOF algorithm is a popular method used in anomaly detection to identify outliers in datasets. It computes anomaly scores by comparing the local density of data points with the densities of their neighbors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76e19ba-b9d7-4286-a8f8-6533f0b9259d",
   "metadata": {},
   "source": [
    "# Q7. What are the key parameters of the Isolation Forest algorithm?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88fd19b3-d042-4e26-8791-d2b925505651",
   "metadata": {},
   "source": [
    "The important key parameters of the Isolation Forest algorithm are as follows:<br>\n",
    "    1. n_estimators :- This parameter specifies the number of trees (or isolating decision trees) to be built in the forest.<br>\n",
    "    2. max_samples:- It determines the maximum number of samples to be used for constructing each tree in the forest. Setting \n",
    "    this value too high may result in overfitting, while setting it too low may lead to underfitting.<br>\n",
    "    3. max_features:- This parameter controls the number of features to consider when splitting a node in each tree. <br>\n",
    "    4. contamination:- This parameter specifies the expected proportion of outliers in the dataset. It is used to set the threshold\n",
    "    for classifying a data point as an outlier.<br>\n",
    "    5. max_depth:- it determines the maximum depth of each decision tree in the forest.<br>\n",
    "    6. bootstrap :- If set to True, each tree in the forest is built using bootstrap sampling (sampling with replacement).<br>\n",
    "    7. random_state :- This parameter controls the randomness of the algorithm. <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04a7061-8213-4b3c-be45-73983b596d80",
   "metadata": {},
   "source": [
    "# Q8. If a data point has only 2 neighbours of the same class within a radius of 0.5, what is its anomaly score using KNN with K=10?  ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15339fe7-815e-4fc5-a94c-46d85d84b6e5",
   "metadata": {},
   "source": [
    "To calculate the anamoly score of a data point using KNN algorithm with k=10 . <br>\n",
    "step 1 :- we have to find the local desity of the point and compare it with the desity of its neighbors\n",
    "the data point is 2 and it distance is less than 0.5 means their density is low .\n",
    "since data point has only two neighbors and k=10 ,we may not have the enough information to accurately \n",
    "find the anamoly score but by seeing the lower value of local desity we may consider the point as outlier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04699c0e-6c8d-489d-af50-390390815a28",
   "metadata": {},
   "source": [
    "# Q9. Using the Isolation Forest algorithm with 100 trees and a dataset of 3000 data points, what is the  anomaly score for a data point that has an average path length of 5.0 compared to the average path  length of the trees?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc88c8d-9c2d-4c81-b538-198f2c1d055c",
   "metadata": {},
   "source": [
    "<font color=\"red\">Answer :- </font> the Isolation Forest algorithm, the anomaly score of a data point is typically computed based on its average path length compared to the average path length of the trees in the forest. A lower average path length indicates that the data point is easier to isolate and thus more likely to be an outlier."
   ]
  },
  {
   "cell_type": "raw",
   "id": "cd4bac61-3377-4bf4-8c51-3b2d0e842129",
   "metadata": {},
   "source": [
    "the average path of the tree in the isolated forest= 2 *(1-1/m)\n",
    "c(3000)= 2* (1-1/3000)\n",
    "c(3000) = 2*2999/3000\n",
    "c(3000) = 1.999334\n",
    "So, the estimated average path length of the trees in the forest is approximately 1.999334\n",
    "If a data point has an average path length of 5.0 compared to this average path length of the trees,\n",
    "E(h(x))=5.0\n",
    "c(m)=1.999334\n",
    "s(x,m)=0.356\n",
    "the anomaly score for a data point with an average path length of 5.0 compared to the average path length of the trees is approximately 0.356."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2018c5f7-5784-453a-8859-2cc9d3922011",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
